{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9dc1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split #dividir el de prueba y entrenamiento como Candy\n",
    "from sklearn.preprocessing import StandardScaler #para poder escalar todas las variables numéricas (independientes), ya que vienen en dimensiones o escalas diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "589f287e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_location</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_reviews_l30d</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_entire_homes.1</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Duplex avec vue, centre ville</td>\n",
       "      <td>Isabelle</td>\n",
       "      <td>2010-10-24</td>\n",
       "      <td>Lyon, France</td>\n",
       "      <td>I'm 47 years old. I enjoy books and arts. I'm ...</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>f</td>\n",
       "      <td>5th Arrondissement</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Nice Flat in the center of Lyon</td>\n",
       "      <td>Clementine</td>\n",
       "      <td>2011-02-26</td>\n",
       "      <td>Lyon, France</td>\n",
       "      <td>Je travaille dans le cinéma et je voyage beauc...</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>f</td>\n",
       "      <td>5th Arrondissement</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Centre of old town,home sweet home</td>\n",
       "      <td>Polali</td>\n",
       "      <td>2011-06-03</td>\n",
       "      <td>Lyon, France</td>\n",
       "      <td>J'ai 34 ans , je suis animatrice auprès de per...</td>\n",
       "      <td>a few days or more</td>\n",
       "      <td>f</td>\n",
       "      <td>5th Arrondissement</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bel apartment, 2 rooms, Lyon center</td>\n",
       "      <td>Sandrine</td>\n",
       "      <td>2011-06-06</td>\n",
       "      <td>Lyon, France</td>\n",
       "      <td>We are a family with 3 daughters, aged 16-14-1...</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>f</td>\n",
       "      <td>1st Arrondissement</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Quartier Terreaux 4/6 pers. Hyper centre / Clim</td>\n",
       "      <td>Giuseppina</td>\n",
       "      <td>2011-07-18</td>\n",
       "      <td>Rhône-Alpes, France</td>\n",
       "      <td>Mon pays d'origine est l'Italie, mais je résid...</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>f</td>\n",
       "      <td>1st Arrondissement</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.88</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             name   host_name  \\\n",
       "0           0                    Duplex avec vue, centre ville    Isabelle   \n",
       "1           1                  Nice Flat in the center of Lyon  Clementine   \n",
       "2           2               Centre of old town,home sweet home      Polali   \n",
       "3           3              Bel apartment, 2 rooms, Lyon center    Sandrine   \n",
       "4           4  Quartier Terreaux 4/6 pers. Hyper centre / Clim  Giuseppina   \n",
       "\n",
       "   host_since        host_location  \\\n",
       "0  2010-10-24         Lyon, France   \n",
       "1  2011-02-26         Lyon, France   \n",
       "2  2011-06-03         Lyon, France   \n",
       "3  2011-06-06         Lyon, France   \n",
       "4  2011-07-18  Rhône-Alpes, France   \n",
       "\n",
       "                                          host_about  host_response_time  \\\n",
       "0  I'm 47 years old. I enjoy books and arts. I'm ...  within a few hours   \n",
       "1  Je travaille dans le cinéma et je voyage beauc...      within an hour   \n",
       "2  J'ai 34 ans , je suis animatrice auprès de per...  a few days or more   \n",
       "3  We are a family with 3 daughters, aged 16-14-1...      within an hour   \n",
       "4  Mon pays d'origine est l'Italie, mais je résid...      within an hour   \n",
       "\n",
       "  host_is_superhost  host_neighbourhood host_identity_verified  ...  \\\n",
       "0                 f  5th Arrondissement                      t  ...   \n",
       "1                 f  5th Arrondissement                      t  ...   \n",
       "2                 f  5th Arrondissement                      t  ...   \n",
       "3                 f  1st Arrondissement                      t  ...   \n",
       "4                 f  1st Arrondissement                      t  ...   \n",
       "\n",
       "  number_of_reviews_l30d review_scores_rating review_scores_cleanliness  \\\n",
       "0                    0.0                 4.70                      4.71   \n",
       "1                    1.0                 4.75                      4.80   \n",
       "2                    0.0                 4.48                      4.27   \n",
       "3                    0.0                 4.78                      4.89   \n",
       "4                    2.0                 4.62                      4.86   \n",
       "\n",
       "  review_scores_checkin review_scores_location calculated_host_listings_count  \\\n",
       "0                  4.78                   4.86                            1.0   \n",
       "1                  4.96                   4.88                            1.0   \n",
       "2                  4.72                   4.86                            1.0   \n",
       "3                  4.89                   4.95                            1.0   \n",
       "4                  4.83                   4.88                            2.0   \n",
       "\n",
       "   calculated_host_listings_count_entire_homes  \\\n",
       "0                                          1.0   \n",
       "1                                          1.0   \n",
       "2                                          1.0   \n",
       "3                                          1.0   \n",
       "4                                          1.0   \n",
       "\n",
       "   calculated_host_listings_count_entire_homes.1  \\\n",
       "0                                            1.0   \n",
       "1                                            1.0   \n",
       "2                                            1.0   \n",
       "3                                            1.0   \n",
       "4                                            1.0   \n",
       "\n",
       "   calculated_host_listings_count_shared_rooms  reviews_per_month  \n",
       "0                                          0.0               0.33  \n",
       "1                                          0.0               0.15  \n",
       "2                                          0.0               0.82  \n",
       "3                                          0.0               0.12  \n",
       "4                                          0.0               2.99  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Francia_limpio.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d9070f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8abc9",
   "metadata": {},
   "source": [
    "## 1. host_identity_verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40383f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df[['availability_365','host_acceptance_rate','host_total_listings_count']] #numérica\n",
    "Var_Dep = df['host_identity_verified'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb804f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['t', 't', 't', ..., 't', 't', 't'], shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbeb47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[   0  383]\n",
      " [   0 2585]]\n",
      "Precisión del modelo \"t\":\n",
      "0.8709568733153639\n",
      "Precisión del modelo \"f\":\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.8709568733153639\n",
      "Sensibilidad del modelo \"t\":\n",
      "1.0\n",
      "Sensibilidad del modelo \"f\":\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='t') \n",
    "print('Precisión del modelo \"t\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='f') \n",
    "print('Precisión del modelo \"f\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='t')\n",
    "print('Sensibilidad del modelo \"t\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='f')\n",
    "print('Sensibilidad del modelo \"f\":')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b4e49",
   "metadata": {},
   "source": [
    "## 2. host_response_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058517cf",
   "metadata": {},
   "source": [
    "**Convertirla a dicotómica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f8fc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a few days or more', 'within a day', 'within a few hours',\n",
       "       'within an hour'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['host_response_time'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17325882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos una variable categórica a dicotómica \n",
    "df ['host_response_time']= df['host_response_time'].replace(['within a day', 'within a few hours','within an hour'],'a day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7185432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df[['host_response_rate','host_acceptance_rate','host_listings_count']] #numérica\n",
    "Var_Dep = df['host_response_time'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91177ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a day', 'a day', 'a day', ..., 'a day', 'a day', 'a day'],\n",
       "      shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[2833    0]\n",
      " [ 135    0]]\n",
      "Precisión del modelo \"a day\":\n",
      "0.9545148247978437\n",
      "Precisión del modelo \"a few days or more\":\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.9545148247978437\n",
      "Sensibilidad del modelo \"a day\":\n",
      "1.0\n",
      "Sensibilidad del modelo \"a few days or more\":\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='a day') \n",
    "print('Precisión del modelo \"a day\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='a few days or more') \n",
    "print('Precisión del modelo \"a few days or more\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 1\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='a day')\n",
    "print('Sensibilidad del modelo \"a day\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 2\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='a few days or more')\n",
    "print('Sensibilidad del modelo \"a few days or more\":')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec310a0e",
   "metadata": {},
   "source": [
    "## 3. host_is_superhost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e949d",
   "metadata": {},
   "source": [
    "**Convertir a dicotómica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f4f373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Desconocido', 'f', 't'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['host_is_superhost'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a21bee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos una variable categórica a dicotómica \n",
    "df ['host_is_superhost']= df['host_is_superhost'].replace(['Desconocido'],'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b474c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df[['availability_365','number_of_reviews','host_listings_count']] #numérica\n",
    "Var_Dep = df['host_is_superhost'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b510da08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['f', 'f', 'f', ..., 'f', 't', 'f'], shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7691800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[2316   79]\n",
      " [ 526   47]]\n",
      "Precisión del modelo \"f\":\n",
      "0.8149190710767066\n",
      "Precisión del modelo \"t\":\n",
      "0.373015873015873\n",
      "Exactitud del modelo:\n",
      "0.7961590296495957\n",
      "Sensibilidad del modelo \"f\":\n",
      "0.9670146137787057\n",
      "Sensibilidad del modelo \"t\":\n",
      "0.08202443280977312\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='f') \n",
    "print('Precisión del modelo \"f\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='t') \n",
    "print('Precisión del modelo \"t\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 1\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='f')\n",
    "print('Sensibilidad del modelo \"f\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 2\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='t')\n",
    "print('Sensibilidad del modelo \"t\":')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0372f91f",
   "metadata": {},
   "source": [
    "## 4. room_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2060e6",
   "metadata": {},
   "source": [
    "**Convertir a dicotómica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8800715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Entire home/apt', 'Hotel room', 'Private room', 'Shared room'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar los valores sin repetirse de una columna\n",
    "unico = np.unique(df['room_type'])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efa45f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos una variable categórica a dicotómica \n",
    "df ['room_type']= df['room_type'].replace(['Hotel room','Private room','Shared room'],'Public or shared room')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "527211fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df[['review_scores_rating','accommodates','price']] #numérica\n",
    "Var_Dep = df['room_type'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "740f1f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Entire home/apt', 'Entire home/apt', 'Entire home/apt', ...,\n",
       "       'Entire home/apt', 'Entire home/apt', 'Entire home/apt'],\n",
       "      shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07daad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[2278   21]\n",
      " [ 534  135]]\n",
      "Precisión del modelo \"Entire home/apt\":\n",
      "0.810099573257468\n",
      "Precisión del modelo \"Public or shared room\":\n",
      "0.8653846153846154\n",
      "Exactitud del modelo:\n",
      "0.8130053908355795\n",
      "Sensibilidad del modelo \"Entire home/apt\":\n",
      "0.9908655937364071\n",
      "Sensibilidad del modelo \"Public or shared room\":\n",
      "0.20179372197309417\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Entire home/apt') \n",
    "print('Precisión del modelo \"Entire home/apt\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Public or shared room') \n",
    "print('Precisión del modelo \"Public or shared room\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 1\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Entire home/apt')\n",
    "print('Sensibilidad del modelo \"Entire home/apt\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 2\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Public or shared room')\n",
    "print('Sensibilidad del modelo \"Public or shared room\":')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17e83b",
   "metadata": {},
   "source": [
    "## 5. host_listings_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c3c01",
   "metadata": {},
   "source": [
    "**Convertir a dicotómica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fa618aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(1.0), np.float64(3.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limite superior e inferior de columna objetivo age\n",
    "Max = df['host_listings_count'].max()\n",
    "Min = df['host_listings_count'].min()\n",
    "Limites =[Min,Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervalos\n",
    "intervalos = np.linspace(0.9,3.1,3) #se agrega un decimal mas/menos para que agarre el rango\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías\n",
    "categorias = ['Una propiedad','Mas de una']\n",
    "\n",
    "#Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['host_listings_count']= pd.cut(x=df['host_listings_count'],bins= intervalos,labels=categorias)\n",
    "df['host_listings_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53d63b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df[['maximum_nights','accommodates','price']] #numérica\n",
    "Var_Dep = df['host_listings_count'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f80d8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Una propiedad', 'Una propiedad', 'Una propiedad', ...,\n",
       "       'Una propiedad', 'Una propiedad', 'Una propiedad'],\n",
       "      shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e77262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[   0  142]\n",
      " [   0 2826]]\n",
      "Precisión del modelo \"Una propiedad\":\n",
      "0.9521563342318059\n",
      "Precisión del modelo \"Mas de una\":\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.9521563342318059\n",
      "Sensibilidad del modelo \"Una propiedad\":\n",
      "1.0\n",
      "Sensibilidad del modelo \"Mas de una\":\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Una propiedad') \n",
    "print('Precisión del modelo \"Una propiedad\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Mas de una') \n",
    "print('Precisión del modelo \"Mas de una\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 1\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Una propiedad')\n",
    "print('Sensibilidad del modelo \"Una propiedad\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 2\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Mas de una')\n",
    "print('Sensibilidad del modelo \"Mas de una\":')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01affe87",
   "metadata": {},
   "source": [
    "## 6. bedrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbeffaf",
   "metadata": {},
   "source": [
    "**Convertir a dicotómica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "188677dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0), np.float64(3.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limite superior e inferior de columna objetivo age\n",
    "Max = df['bedrooms'].max()\n",
    "Min = df['bedrooms'].min()\n",
    "Limites =[Min,Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0188606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervalos\n",
    "intervalos = np.linspace(-1,3.1,3) #se agrega un decimal mas/menos para que agarre el rango\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías\n",
    "categorias = ['Una habitacion','Mas de una']\n",
    "\n",
    "#Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['bedrooms']= pd.cut(x=df['bedrooms'],bins= intervalos,labels=categorias)\n",
    "df['bedrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "312546d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df[['maximum_nights','accommodates','price']] #numérica\n",
    "Var_Dep = df['bedrooms'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e47a3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Una habitacion', 'Una habitacion', 'Una habitacion', ...,\n",
       "       'Una habitacion', 'Mas de una', 'Una habitacion'],\n",
       "      shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fe0897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[ 339  487]\n",
      " [  67 2075]]\n",
      "Precisión del modelo \"Una habitación\":\n",
      "0.8099141295862607\n",
      "Precisión del modelo \"Más de una\":\n",
      "0.8349753694581281\n",
      "Exactitud del modelo:\n",
      "0.8133423180592992\n",
      "Sensibilidad del modelo \"Una habitación\":\n",
      "0.9687208216619981\n",
      "Sensibilidad del modelo \"Más de una\":\n",
      "0.41041162227602906\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Una habitacion') \n",
    "print('Precisión del modelo \"Una habitación\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Mas de una') \n",
    "print('Precisión del modelo \"Más de una\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 1\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Una habitacion')\n",
    "print('Sensibilidad del modelo \"Una habitación\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 2\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Mas de una')\n",
    "print('Sensibilidad del modelo \"Más de una\":')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e910239",
   "metadata": {},
   "source": [
    "## 7. beds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508aeb0a",
   "metadata": {},
   "source": [
    "**Convertir a dicotómica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5049e274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0), np.float64(3.0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limite superior e inferior de columna objetivo age\n",
    "Max = df['beds'].max()\n",
    "Min = df['beds'].min()\n",
    "Limites =[Min,Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6165024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervalos\n",
    "intervalos = np.linspace(-1,3.1,3) #se agrega un decimal mas/menos para que agarre el rango\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías\n",
    "categorias = ['Una cama','Mas de una']\n",
    "\n",
    "#Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['beds']= pd.cut(x=df['beds'],bins= intervalos,labels=categorias)\n",
    "df['beds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01e72b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df[['maximum_nights','accommodates','price']] #numérica\n",
    "Var_Dep = df['beds'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4294455e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Una cama', 'Una cama', 'Una cama', ..., 'Mas de una', 'Una cama',\n",
       "       'Una cama'], shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a6e9916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[ 254  532]\n",
      " [ 204 1978]]\n",
      "Precisión del modelo \"Una cama\":\n",
      "0.7880478087649403\n",
      "Precisión del modelo \"Más de una\":\n",
      "0.5545851528384279\n",
      "Exactitud del modelo:\n",
      "0.7520215633423181\n",
      "Sensibilidad del modelo \"Una cama\":\n",
      "0.9065077910174152\n",
      "Sensibilidad del modelo \"Más de una\":\n",
      "0.3231552162849873\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Una cama') \n",
    "print('Precisión del modelo \"Una cama\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Mas de una') \n",
    "print('Precisión del modelo \"Más de una\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 1\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Una cama')\n",
    "print('Sensibilidad del modelo \"Una cama\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 2\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Mas de una')\n",
    "print('Sensibilidad del modelo \"Más de una\":')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f374659c",
   "metadata": {},
   "source": [
    "## 8. number_of_reviews_l30d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d6eda",
   "metadata": {},
   "source": [
    "**Convertir a dicotómica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a529927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.0), np.float64(2.0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limite superior e inferior de columna objetivo age\n",
    "Max = df['number_of_reviews_l30d'].max()\n",
    "Min = df['number_of_reviews_l30d'].min()\n",
    "Limites =[Min,Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d98d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervalos\n",
    "intervalos = np.linspace(-1,2.1,3) #se agrega un decimal mas/menos para que agarre el rango\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías\n",
    "categorias = ['No tiene','Ultimos 30 dias']\n",
    "\n",
    "#Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['number_of_reviews_l30d']= pd.cut(x=df['number_of_reviews_l30d'],bins= intervalos,labels=categorias)\n",
    "df['number_of_reviews_l30d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4690208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df[['availability_365','host_acceptance_rate','price']] #numérica\n",
    "Var_Dep = df['number_of_reviews_l30d'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a6b11b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No tiene', 'Ultimos 30 dias', 'No tiene', ..., 'No tiene',\n",
       "       'No tiene', 'No tiene'], shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "917fee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[2382   34]\n",
      " [ 539   13]]\n",
      "Precisión del modelo \"No tiene\":\n",
      "0.8154741526874358\n",
      "Precisión del modelo \"Ultimos 30 dias\":\n",
      "0.2765957446808511\n",
      "Exactitud del modelo:\n",
      "0.8069407008086253\n",
      "Sensibilidad del modelo \"No tiene\":\n",
      "0.9859271523178808\n",
      "Sensibilidad del modelo \"Ultimos 30 dias\":\n",
      "0.02355072463768116\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='No tiene') \n",
    "print('Precisión del modelo \"No tiene\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Ultimos 30 dias') \n",
    "print('Precisión del modelo \"Ultimos 30 dias\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 1\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='No tiene')\n",
    "print('Sensibilidad del modelo \"No tiene\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 2\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Ultimos 30 dias')\n",
    "print('Sensibilidad del modelo \"Ultimos 30 dias\":')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a523e6d5",
   "metadata": {},
   "source": [
    "## 9.availability_30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d64f1",
   "metadata": {},
   "source": [
    "**Convertir a dicotómica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45f0a017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0), np.int64(30)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limite superior e inferior de columna objetivo age\n",
    "Max = df['availability_30'].max()\n",
    "Min = df['availability_30'].min()\n",
    "Limites =[Min,Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe40078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervalos\n",
    "intervalos = np.linspace(-1,30.1,3) #se agrega un decimal mas/menos para que agarre el rango\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías\n",
    "categorias = ['Hasta 14 dias','De 14 a 30 dias']\n",
    "\n",
    "#Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df['availability_30']= pd.cut(x=df['availability_30'],bins= intervalos,labels=categorias)\n",
    "df['availability_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55b8895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df[['number_of_reviews','host_acceptance_rate','price']] #numérica\n",
    "Var_Dep = df['availability_30'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed3ee986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hasta 14 dias', 'Hasta 14 dias', 'Hasta 14 dias', ...,\n",
       "       'Hasta 14 dias', 'Hasta 14 dias', 'Hasta 14 dias'],\n",
       "      shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4904ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[  33  918]\n",
      " [  30 1987]]\n",
      "Precisión del modelo \"Hasta 14 dias\":\n",
      "0.6839931153184166\n",
      "Precisión del modelo \"De 14 a 30 dias\":\n",
      "0.5238095238095238\n",
      "Exactitud del modelo:\n",
      "0.6805929919137467\n",
      "Sensibilidad del modelo \"Hasta 14 dias\":\n",
      "0.985126425384234\n",
      "Sensibilidad del modelo \"De 14 a 30 dias\":\n",
      "0.03470031545741325\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Hasta 14 dias') \n",
    "print('Precisión del modelo \"Hasta 14 dias\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='De 14 a 30 dias') \n",
    "print('Precisión del modelo \"De 14 a 30 dias\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 1\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Hasta 14 dias')\n",
    "print('Sensibilidad del modelo \"Hasta 14 dias\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 2\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='De 14 a 30 dias')\n",
    "print('Sensibilidad del modelo \"De 14 a 30 dias\":')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39bb482",
   "metadata": {},
   "source": [
    "## 10. accommodates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72059eb0",
   "metadata": {},
   "source": [
    "**Convertir a dicotómica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "19f393c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(1.0), np.float64(7.0)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limite superior e inferior de columna objetivo age\n",
    "Max = df1['accommodates'].max()\n",
    "Min = df1['accommodates'].min()\n",
    "Limites =[Min,Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bd2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervalos\n",
    "intervalos = np.linspace(0.9,7.1,3) #se agrega un decimal mas/menos para que agarre el rango\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías\n",
    "categorias = ['Hasta 4 personas','De 4 a 7 personas']\n",
    "\n",
    "#Ajustar maximo de filas\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df1['accommodates']= pd.cut(x=df1['accommodates'],bins= intervalos,labels=categorias)\n",
    "df1['accommodates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afc15106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaramos las variables dependientes e independientes para regresión logística\n",
    "#Dependiente es dicotómica y las independientes de tipo numérico\n",
    "Vars_Indep = df1[['beds','price','bedrooms']] #numérica\n",
    "Var_Dep = df1['accommodates'] #dicotómica\n",
    "\n",
    "#Redefinir\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "#test size es que queremos el 30%, podemos irle cambiando\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.3, random_state =None) #Va a asignar aleatoriamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e20c2e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hasta 4 personas', 'De 4 a 7 personas', 'De 4 a 7 personas', ...,\n",
       "       'Hasta 4 personas', 'De 4 a 7 personas', 'De 4 a 7 personas'],\n",
       "      shape=(2968,), dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se escalan los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algortimo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Emtrenamos el modelo\n",
    "algoritmo.fit(X_train,y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a6076f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión\n",
      "[[ 818  346]\n",
      " [ 220 1584]]\n",
      "Precisión del modelo \"Hasta 4 personas\":\n",
      "0.8207253886010363\n",
      "Precisión del modelo \"De 4 a 7 personas\":\n",
      "0.7880539499036608\n",
      "Exactitud del modelo:\n",
      "0.8092991913746631\n",
      "Sensibilidad del modelo \"Hasta 4 personas\":\n",
      "0.8780487804878049\n",
      "Sensibilidad del modelo \"De 4 a 7 personas\":\n",
      "0.7027491408934707\n"
     ]
    }
   ],
   "source": [
    "#Verifico la matriz de confunsión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix (y_test, y_pred)\n",
    "print('Matriz de Confusión')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión Var 1\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='Hasta 4 personas') \n",
    "print('Precisión del modelo \"Hasta 4 personas\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión Var 2\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary',pos_label='De 4 a 7 personas') \n",
    "print('Precisión del modelo \"De 4 a 7 personas\":')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test,y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 1\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='Hasta 4 personas')\n",
    "print('Sensibilidad del modelo \"Hasta 4 personas\":')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo Var 2\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test,y_pred, average ='binary',pos_label='De 4 a 7 personas')\n",
    "print('Sensibilidad del modelo \"De 4 a 7 personas\":')\n",
    "print(sensibilidad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
